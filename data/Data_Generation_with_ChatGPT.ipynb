{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-03-17T03:08:34.299671Z",
     "iopub.status.busy": "2023-03-17T03:08:34.299276Z",
     "iopub.status.idle": "2023-03-17T03:08:40.413917Z",
     "shell.execute_reply": "2023-03-17T03:08:40.413135Z",
     "shell.execute_reply.started": "2023-03-17T03:08:34.299638Z"
    },
    "id": "m6SpDfR39dNt",
    "outputId": "a5b7b715-f081-429c-cc86-d7f999d09fcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-0.27.2-py3-none-any.whl (70 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.28.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from openai) (3.8.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.20->openai) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.20->openai) (2019.11.28)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.8.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (18.2.0)\n",
      "Installing collected packages: openai\n",
      "Successfully installed openai-0.27.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T03:08:43.929687Z",
     "iopub.status.busy": "2023-03-17T03:08:43.928458Z",
     "iopub.status.idle": "2023-03-17T03:08:44.745624Z",
     "shell.execute_reply": "2023-03-17T03:08:44.742345Z",
     "shell.execute_reply.started": "2023-03-17T03:08:43.929650Z"
    },
    "id": "vKSRBdgFwFVW"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "openai.api_key = \"OPEN_AI_KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vRkq17j1eOhO"
   },
   "source": [
    "# Seed Generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eGmSF59WvaKW"
   },
   "outputs": [],
   "source": [
    "# Seed Generation\n",
    "\n",
    "\n",
    "# German\n",
    "def gen_seed_de():\n",
    "  ret = []\n",
    "  nv = ['Substantive', 'Verben']\n",
    "  for word in nv:\n",
    "    response = openai.ChatCompletion.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=[\n",
    "          {\"role\": \"system\", \"content\": \"Generieren Sie 600 einzigartige zufällige {}, die jeweils durch ein Komma getrennt sind\".format(word)}\n",
    "      ]\n",
    "    )\n",
    "    ret += response.choices[0].message.content.strip().split(',')\n",
    "  df = pd.DataFrame(ret)[0].unique()\n",
    "  return df\n",
    "\n",
    "# Galician\n",
    "def gen_seed_gl():\n",
    "  ret = []\n",
    "  nv = ['substantivos', 'verbos']\n",
    "  for word in nv:\n",
    "    response = openai.ChatCompletion.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=[\n",
    "          {\"role\": \"system\", \"content\": \"Xera 600 {} aleatorios únicos separados por coma\".format(word)}\n",
    "      ]\n",
    "    )\n",
    "    ret += response.choices[0].message.content.strip().split(',')\n",
    "  df = pd.DataFrame(ret)[0].unique()\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HKm6Rda-HyuU",
    "outputId": "1a6eec2e-a7bb-4a0e-8f02-b3d1dac1a2d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German seeds:  1043\n"
     ]
    }
   ],
   "source": [
    "seeds_de = pd.DataFrame(gen_seed_de())\n",
    "print('German seeds: ', len(seeds_de))\n",
    "seeds_de.to_csv('synthetic_data/seeds/seeds_de.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-03-11T05:19:14.056288Z",
     "iopub.status.busy": "2023-03-11T05:19:14.055693Z",
     "iopub.status.idle": "2023-03-11T05:21:54.727641Z",
     "shell.execute_reply": "2023-03-11T05:21:54.726825Z",
     "shell.execute_reply.started": "2023-03-11T05:19:14.056260Z"
    },
    "id": "3gp8iIuNH0sm",
    "outputId": "5f9400bd-d02d-4f73-9d8d-24ddcbd8b284"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Galician seeds:  1094\n"
     ]
    }
   ],
   "source": [
    "seeds_gl = pd.DataFrame(gen_seed_gl())\n",
    "print('Galician seeds: ', len(seeds_gl))\n",
    "seeds_gl.to_csv('synthetic_data/seeds/seeds_gl.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TkJrEjnzeTaG"
   },
   "source": [
    "# Sentence Generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-14T03:18:52.895548Z",
     "iopub.status.busy": "2023-03-14T03:18:52.895036Z",
     "iopub.status.idle": "2023-03-14T03:18:52.934441Z",
     "shell.execute_reply": "2023-03-14T03:18:52.933645Z",
     "shell.execute_reply.started": "2023-03-14T03:18:52.895520Z"
    },
    "id": "X_zA9mtXHIuH"
   },
   "outputs": [],
   "source": [
    "# Load seeds\n",
    "\n",
    "seeds_de = pd.read_csv('synthetic_data/seeds/seeds_de.csv', index_col=0)\n",
    "seeds_gl = pd.read_csv('synthetic_data/seeds/seeds_gl.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-14T03:18:54.713960Z",
     "iopub.status.busy": "2023-03-14T03:18:54.713214Z",
     "iopub.status.idle": "2023-03-14T03:18:54.722727Z",
     "shell.execute_reply": "2023-03-14T03:18:54.721985Z",
     "shell.execute_reply.started": "2023-03-14T03:18:54.713917Z"
    },
    "id": "sJ3gMFES4N66"
   },
   "outputs": [],
   "source": [
    "# Generate sentences\n",
    "\n",
    "# German\n",
    "def sentence_de_openai(key):\n",
    "  response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Generieren Sie an der Eingabeaufforderung 100 separate Sätze, die durch ein Semikolon getrennt sind\"},\n",
    "        {\"role\": \"user\", \"content\": key},\n",
    "        {\"role\": \"assistant\", \"content\": \"Gärten und Terrassen;Tacos sind gut.;\"}\n",
    "    ]\n",
    "  )\n",
    "  global de_tokens \n",
    "  de_tokens += int(response['usage']['completion_tokens'])\n",
    "  return pd.DataFrame(response.choices[0].message.content.strip().split(';'))[0].unique()\n",
    "\n",
    "# Galician\n",
    "def sentence_gl_openai(key):\n",
    "  response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Xera 100 frases individuais, separadas só por un punto e coma, desde o indicador\"},\n",
    "        {\"role\": \"user\", \"content\": key},\n",
    "        {\"role\": \"assistant\", \"content\": \"Éste é o problema.;Volvín á sala de chat.;\"}\n",
    "    ]\n",
    "  )\n",
    "  global gl_tokens \n",
    "  gl_tokens += int(response['usage']['completion_tokens'])\n",
    "  return pd.DataFrame(response.choices[0].message.content.strip().split(';'))[0].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_tokens = 0\n",
    "ret = pd.DataFrame()\n",
    "\n",
    "# Run the generation function on each seed\n",
    "for word in seeds_de['0']:\n",
    "    new_s = pd.DataFrame(sentence_de_openai(word))\n",
    "    try:\n",
    "      if (len(new_s) > 10):\n",
    "        ret = pd.concat([ret, new_s], axis=0)\n",
    "    except:\n",
    "        pass       # do nothing with exception and move on, just don't crash haha\n",
    "\n",
    "# delete duplicates, shuffle\n",
    "ret = pd.DataFrame(ret[0].unique()).sample(frac = 1)\n",
    "ret.to_csv('synthetic_data/raw/de-en.de', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl_tokens = 0\n",
    "ret = pd.DataFrame()\n",
    "for word in seeds_gl['0']:\n",
    "    new_s = pd.DataFrame(sentence_gl_openai(word))\n",
    "    try: \n",
    "      if (len(new_s) > 10):\n",
    "        ret = pd.concat([ret, new_s], axis=0)\n",
    "    except:\n",
    "        pass      # do nothing with exception and move on, just don't crash haha\n",
    "\n",
    "# delete duplicates, shuffle\n",
    "ret = pd.DataFrame(ret[0].unique()).sample(frac = 1)\n",
    "ret.to_csv('synthetic_data/raw/gl-en.gl', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FnkEtQv2pRml"
   },
   "source": [
    "# Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T03:08:50.922128Z",
     "iopub.status.busy": "2023-03-17T03:08:50.920551Z",
     "iopub.status.idle": "2023-03-17T03:08:50.927803Z",
     "shell.execute_reply": "2023-03-17T03:08:50.926654Z",
     "shell.execute_reply.started": "2023-03-17T03:08:50.922091Z"
    },
    "id": "g9DOAqCp8_Dr"
   },
   "outputs": [],
   "source": [
    "# Translate from German\n",
    "def translate_de(string):\n",
    "  response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Translate from German to English\"},\n",
    "        {\"role\": \"user\", \"content\": string}\n",
    "    ]\n",
    ")\n",
    "  return response.choices[0].message.content\n",
    "\n",
    "\n",
    "# Translate from Galician\n",
    "def translate_gl(string):\n",
    "  response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Translate from Galician to English\"},\n",
    "        {\"role\": \"user\", \"content\": string}\n",
    "    ]\n",
    ")\n",
    "  return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('synthetic_data/train/de-en.de', header=None)\n",
    "print(len(df))\n",
    "#print(len(df_eng))\n",
    "df.insert(1, 'eng', [0]*len(df))\n",
    "for i in range(len(df)):\n",
    "        try:\n",
    "            translated = translate_de(df[0].iloc[i])\n",
    "            df['eng'].iloc[i] = translated\n",
    "            print(df.iloc[i])\n",
    "        except:\n",
    "            # append empty string if errors\n",
    "            print(i)\n",
    "            pass\n",
    "# remove newline chars\n",
    "for i in range(len(df)):\n",
    "    df['eng'][i] = df['eng'][i].replace('\\n', ' ')\n",
    "pd.DataFrame(df['eng']).to_csv('synthetic_data/train/de-en.en', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S2q-jdDR-lH-"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('synthetic_data/train/gl-en.gl', header=None)\n",
    "df.insert(1, 'eng', [0]*len(df))\n",
    "print(len(df))\n",
    "for i in range(len(df)):\n",
    "      try:\n",
    "          translated = translate_gl(df[0].iloc[i])\n",
    "          df['eng'].iloc[i] = translated\n",
    "          print(df.iloc[i])\n",
    "      except:\n",
    "          # append empty string if errors\n",
    "          print(i)\n",
    "          pass\n",
    "\n",
    "# remove newline chars\n",
    "for i in range(len(df)):\n",
    "    df['eng'][i] = df['eng'][i].replace('\\n', ' ')\n",
    "pd.DataFrame(df['eng']).to_csv('synthetic_data/train/gl-en.en', header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
